{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/users/junzheyin/iris/src', '/users/junzheyin/iris/src/models', '/users/junzheyin/anaconda3/envs/iris/lib/python38.zip', '/users/junzheyin/anaconda3/envs/iris/lib/python3.8', '/users/junzheyin/anaconda3/envs/iris/lib/python3.8/lib-dynload', '', '/users/junzheyin/.local/lib/python3.8/site-packages', '/users/junzheyin/anaconda3/envs/iris/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/users/junzheyin/iris/src')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Tuple\n",
    "\n",
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from dataset import Batch\n",
    "from tokenizer.lpips import LPIPS\n",
    "from tokenizer.nets import Encoder, Decoder\n",
    "from utils import LossWithIntermediateLosses\n",
    "\n",
    "batch=1\n",
    "@dataclass\n",
    "class TokenizerEncoderOutput:\n",
    "    z: torch.FloatTensor\n",
    "    z_quantized: torch.FloatTensor\n",
    "    tokens: torch.LongTensor\n",
    "\n",
    "\n",
    "class Tokenizer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, encoder: Encoder, decoder: Decoder, with_lpips: bool) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.encoder = encoder\n",
    "        self.pre_quant_conv = torch.nn.Conv2d(encoder.config.z_channels, embed_dim, 1)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.post_quant_conv = torch.nn.Conv2d(embed_dim, decoder.config.z_channels, 1)\n",
    "        self.decoder = decoder\n",
    "        self.embedding.weight.data.uniform_(-1.0 / vocab_size, 1.0 / vocab_size)\n",
    "        self.lpips = LPIPS().eval() if with_lpips else None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"tokenizer\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor, should_preprocess: bool = False, should_postprocess: bool = False) -> Tuple[torch.Tensor]:\n",
    "        outputs = self.encode(x, should_preprocess)\n",
    "        decoder_input = outputs.z + (outputs.z_quantized - outputs.z).detach()\n",
    "        reconstructions = self.decode(decoder_input, should_postprocess)\n",
    "        return outputs.z, outputs.z_quantized, reconstructions\n",
    "\n",
    "    def compute_loss(self, x, **kwargs: Any) -> LossWithIntermediateLosses:\n",
    "        assert self.lpips is not None\n",
    "        observations = x\n",
    "        z, z_quantized, reconstructions = self(observations, should_preprocess=False, should_postprocess=False)\n",
    "\n",
    "        # Codebook loss. Notes:\n",
    "        # - beta position is different from taming and identical to original VQVAE paper\n",
    "        # - VQVAE uses 0.25 by default\n",
    "        beta = 1.0\n",
    "        commitment_loss = (z.detach() - z_quantized).pow(2).mean() + beta * (z - z_quantized.detach()).pow(2).mean()\n",
    "\n",
    "        reconstruction_loss = torch.abs(observations - reconstructions).mean()\n",
    "        perceptual_loss = torch.mean(self.lpips(observations, reconstructions))\n",
    "\n",
    "        return LossWithIntermediateLosses(commitment_loss=commitment_loss, reconstruction_loss=reconstruction_loss,perceptual_loss=perceptual_loss)\n",
    "\n",
    "    def encode(self, x: torch.Tensor, should_preprocess: bool = False) -> TokenizerEncoderOutput:\n",
    "        if should_preprocess:\n",
    "            x = self.preprocess_input(x)\n",
    "        #print(\"Shape of x:\", x.shape)\n",
    "        shape = x.shape  # (..., C, H, W)\n",
    "        x = x.view(-1, *shape[-3:])\n",
    "        #print(\"Shape of x as (x_view):\", x.shape)\n",
    "        z = self.encoder(x)\n",
    "        #print(\"Shape of z:\",z.shape)\n",
    "        z = self.pre_quant_conv(z)\n",
    "        b, e, h, w = z.shape\n",
    "        z_flattened = rearrange(z, 'b e h w -> (b h w) e')\n",
    "        #print(\"Shape of z_flattend:\",z_flattened.shape)\n",
    "        dist_to_embeddings = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + torch.sum(self.embedding.weight**2, dim=1) - 2 * torch.matmul(z_flattened, self.embedding.weight.t())\n",
    "\n",
    "        tokens = dist_to_embeddings.argmin(dim=-1)\n",
    "        #print(\"Shape of tokens:\",tokens.shape)\n",
    "        z_q = rearrange(self.embedding(tokens), '(b h w) e -> b e h w', b=b, e=e, h=h, w=w).contiguous()\n",
    "        #print(\"Shape of z_q:\",z_q.shape)\n",
    "        # Reshape to original\n",
    "        z = z.reshape(*shape[:-3], *z.shape[1:])\n",
    "        #print(\"Shape of reshaped z:\", z.shape)\n",
    "        z_q = z_q.reshape(*shape[:-3], *z_q.shape[1:])\n",
    "        #print(\"Shape of reshaped z_q:\", z_q.shape)\n",
    "        tokens = tokens.reshape(*shape[:-3], -1)\n",
    "        #print(\"Shape of tokens:\", tokens.shape)\n",
    "\n",
    "        return TokenizerEncoderOutput(z, z_q, tokens)\n",
    "\n",
    "    def decode(self, z_q: torch.Tensor, should_postprocess: bool = False) -> torch.Tensor:\n",
    "        shape = z_q.shape  # (..., E, h, w)\n",
    "        z_q = z_q.view(-1, *shape[-3:])\n",
    "        z_q = self.post_quant_conv(z_q)\n",
    "        rec = self.decoder(z_q)\n",
    "        rec = rec.reshape(*shape[:-3], *rec.shape[1:])\n",
    "        if should_postprocess:\n",
    "            rec = self.postprocess_output(rec)\n",
    "        return rec\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode_decode(self, x: torch.Tensor, should_preprocess: bool = False, should_postprocess: bool = False) -> torch.Tensor:\n",
    "        z_q = self.encode(x, should_preprocess).z_quantized\n",
    "        return self.decode(z_q, should_postprocess)\n",
    "\n",
    "    def preprocess_input(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"x is supposed to be channels first and in [0, 1]\"\"\"\n",
    "        return x.mul(2).sub(1)\n",
    "\n",
    "    def postprocess_output(self, y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"y is supposed to be channels first and in [-1, 1]\"\"\"\n",
    "        return y.add(1).div(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "## Configuration file for the Endocer and Decoder\n",
    "@dataclass\n",
    "class EncoderDecoderConfig:\n",
    "    resolution: int\n",
    "    in_channels: int\n",
    "    z_channels: int\n",
    "    ch: int\n",
    "    ch_mult: List[int]\n",
    "    num_res_blocks: int\n",
    "    attn_resolutions: List[int]\n",
    "    out_ch: int\n",
    "    dropout: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer : shape of latent is (256, 8, 8).\n",
      "Encoder(\n",
      "  (conv_in): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (down): ModuleList(\n",
      "    (0): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (downsample): Downsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (downsample): Downsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (2): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (downsample): Downsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (3): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (downsample): Downsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (4): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (downsample): Downsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (5): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList(\n",
      "        (0): AttnBlock(\n",
      "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): AttnBlock(\n",
      "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mid): Module(\n",
      "    (block_1): ResnetBlock(\n",
      "      (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (attn_1): AttnBlock(\n",
      "      (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (block_2): ResnetBlock(\n",
      "      (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "  (conv_out): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Decoder(\n",
      "  (conv_in): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (mid): Module(\n",
      "    (block_1): ResnetBlock(\n",
      "      (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (attn_1): AttnBlock(\n",
      "      (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (block_2): ResnetBlock(\n",
      "      (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (up): ModuleList(\n",
      "    (0): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "    )\n",
      "    (1): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (upsample): Upsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (upsample): Upsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (upsample): Upsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList()\n",
      "      (upsample): Upsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): Module(\n",
      "      (block): ModuleList(\n",
      "        (0): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (attn): ModuleList(\n",
      "        (0): AttnBlock(\n",
      "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): AttnBlock(\n",
      "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): AttnBlock(\n",
      "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsample): Upsample(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "  (conv_out): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(EncoderDecoderConfig(resolution=256,\n",
    "                                       in_channels=1,\n",
    "                                        z_channels=256,\n",
    "                                        ch=128,\n",
    "                                        ch_mult= [1, 1, 1, 2, 2, 4],\n",
    "                                        num_res_blocks= 2,\n",
    "                                        attn_resolutions= [8],\n",
    "                                        out_ch= 1,\n",
    "                                        dropout= 0.0))\n",
    "decoder=Decoder(EncoderDecoderConfig(resolution=256,\n",
    "                                       in_channels=1,\n",
    "                                        z_channels=256,\n",
    "                                        ch=128,\n",
    "                                        ch_mult=[1, 1, 1, 2, 2, 4 ],\n",
    "                                        num_res_blocks= 2,\n",
    "                                        attn_resolutions= [8],\n",
    "                                        out_ch= 1,\n",
    "                                        dropout= 0.0))\n",
    "vocab_size = 1024 # actual vocabulary size \n",
    "embed_dim = 64  # the desired embedding dimension of the codebook (coebook dim)\n",
    "Tokenizer = Tokenizer(vocab_size, embed_dim, encoder, decoder, with_lpips=True)\n",
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer\n"
     ]
    }
   ],
   "source": [
    "print(Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "checkpoint = torch.load('/space/junzheyin/check4/vqvae_checkpoint_epoch51', map_location=device)\n",
    "Tokenizer.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from kv_caching import KeysValues, KVCache\n",
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    tokens_per_block: int\n",
    "    max_blocks: int\n",
    "    attention: str\n",
    "\n",
    "    num_layers: int\n",
    "    num_heads: int\n",
    "    embed_dim: int\n",
    "\n",
    "    embed_pdrop: float\n",
    "    resid_pdrop: float\n",
    "    attn_pdrop: float\n",
    "\n",
    "    @property\n",
    "    def max_tokens(self):\n",
    "        return self.tokens_per_block * self.max_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.drop = nn.Dropout(config.embed_pdrop)\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.num_layers)])\n",
    "        self.ln_f = nn.LayerNorm(config.embed_dim)\n",
    "\n",
    "    def generate_empty_keys_values(self, n: int, max_tokens: int) -> KeysValues:\n",
    "        device = self.ln_f.weight.device  # Assumption that all submodules are on the same device\n",
    "        return KeysValues(n, self.config.num_heads, max_tokens, self.config.embed_dim, self.config.num_layers, device)\n",
    "\n",
    "    def forward(self, sequences: torch.Tensor, past_keys_values: Optional[KeysValues] = None) -> torch.Tensor:\n",
    "        assert past_keys_values is None or len(past_keys_values) == len(self.blocks)\n",
    "        x = self.drop(sequences)\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            x = block(x, None if past_keys_values is None else past_keys_values[i])\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(config.embed_dim)\n",
    "        self.attn = SelfAttention(config)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.embed_dim, 4 * config.embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * config.embed_dim, config.embed_dim),\n",
    "            nn.Dropout(config.resid_pdrop),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, past_keys_values: Optional[KeysValues] = None) -> torch.Tensor:\n",
    "        x_attn = self.attn(self.ln1(x), past_keys_values)\n",
    "        x = x + x_attn\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig) -> None:\n",
    "        super().__init__()\n",
    "        assert config.embed_dim % config.num_heads == 0\n",
    "        assert config.attention in ('causal', 'block_causal')\n",
    "        self.num_heads = config.num_heads\n",
    "        self.key = nn.Linear(config.embed_dim, config.embed_dim)\n",
    "        self.query = nn.Linear(config.embed_dim, config.embed_dim)\n",
    "        self.value = nn.Linear(config.embed_dim, config.embed_dim)\n",
    "        self.attn_drop = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_drop = nn.Dropout(config.resid_pdrop)\n",
    "        self.proj = nn.Linear(config.embed_dim, config.embed_dim)\n",
    "\n",
    "        causal_mask = torch.tril(torch.ones(config.max_tokens, config.max_tokens))\n",
    "        block_causal_mask = torch.max(causal_mask, torch.block_diag(*[torch.ones(config.tokens_per_block, config.tokens_per_block) for _ in range(config.max_blocks)]))\n",
    "        self.register_buffer('mask', causal_mask if config.attention == 'causal' else block_causal_mask)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, kv_cache: Optional[KVCache] = None) -> torch.Tensor:\n",
    "        B, T, C = x.size()\n",
    "        if kv_cache is not None:\n",
    "            b, nh, L, c = kv_cache.shape\n",
    "            assert nh == self.num_heads and b == B and c * nh == C\n",
    "        else:\n",
    "            L = 0\n",
    "\n",
    "        q = self.query(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2)   # (B, nh, T, hs)\n",
    "        k = self.key(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2)     # (B, nh, T, hs)\n",
    "        v = self.value(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2)   # (B, nh, T, hs)\n",
    "\n",
    "        if kv_cache is not None:\n",
    "            kv_cache.update(k, v)\n",
    "            k, v = kv_cache.get()\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.mask[L:L + T, :L + T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_drop(att)\n",
    "        y = att @ v\n",
    "        y = rearrange(y, 'b h t e -> b t (h e)')\n",
    "\n",
    "        y = self.resid_drop(self.proj(y))\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfromer= Transformer(TransformerConfig(tokens_per_block=768,\n",
    "                               max_blocks=3,\n",
    "                               attention='causal',\n",
    "                               num_layers=6,\n",
    "                               num_heads=8,\n",
    "                               embed_dim=256,\n",
    "                               embed_pdrop=0.1,\n",
    "                               resid_pdrop=0.1,\n",
    "                               attn_pdrop=0.1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): SelfAttention(\n",
      "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): SelfAttention(\n",
      "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): SelfAttention(\n",
      "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): SelfAttention(\n",
      "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): SelfAttention(\n",
      "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): SelfAttention(\n",
      "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transfromer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mslicer\u001b[39;00m \u001b[39mimport\u001b[39;00m Embedder, Head\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizer\u001b[39;00m \u001b[39mimport\u001b[39;00m Tokenizer\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformer\u001b[39;00m \u001b[39mimport\u001b[39;00m Transformer, TransformerConfig\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m init_weights, LossWithIntermediateLosses\n\u001b[1;32m     17\u001b[0m \u001b[39m@dataclass\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mWorldModelOutput\u001b[39;00m:\n",
      "File \u001b[0;32m~/iris/src/models/transformer.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m functional \u001b[39mas\u001b[39;00m F\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mkv_caching\u001b[39;00m \u001b[39mimport\u001b[39;00m KeysValues, KVCache\n\u001b[1;32m     17\u001b[0m \u001b[39m@dataclass\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTransformerConfig\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     tokens_per_block: \u001b[39mint\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from dataset import Batch\n",
    "from kv_caching import KeysValues\n",
    "from slicer import Embedder, Head\n",
    "#from tokenizer import Tokenizer\n",
    "from transformer import Transformer, TransformerConfig\n",
    "from utils import init_weights, LossWithIntermediateLosses\n",
    "\n",
    "Batch = Dict[str, torch.Tensor]\n",
    "\n",
    "@dataclass\n",
    "class WorldModelOutput:\n",
    "    output_sequence: torch.FloatTensor\n",
    "    logits_observations: torch.FloatTensor\n",
    "    logits_rewards: torch.FloatTensor\n",
    "    logits_ends: torch.FloatTensor\n",
    "\n",
    "\n",
    "class WorldModel(nn.Module):\n",
    "    def __init__(self, obs_vocab_size: int, config: TransformerConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.obs_vocab_size = obs_vocab_size\n",
    "        self.config = config\n",
    "        self.transformer = Transformer(config)\n",
    "\n",
    "        all_but_last_obs_tokens_pattern = torch.ones(config.tokens_per_block)\n",
    "        all_but_last_obs_tokens_pattern[-2] = 0\n",
    "        act_tokens_pattern = torch.zeros(self.config.tokens_per_block)\n",
    "        act_tokens_pattern[-1] = 1\n",
    "        obs_tokens_pattern = 1 - act_tokens_pattern\n",
    "\n",
    "        self.pos_emb = nn.Embedding(config.max_tokens, config.embed_dim)\n",
    "\n",
    "        self.embedder = Embedder(\n",
    "            max_blocks=config.max_blocks,\n",
    "            block_masks=[obs_tokens_pattern],\n",
    "            embedding_tables=nn.ModuleList([nn.Embedding(obs_vocab_size, config.embed_dim)])\n",
    "        )\n",
    "\n",
    "        self.head_observations = Head(\n",
    "            max_blocks=config.max_blocks,\n",
    "            block_mask=all_but_last_obs_tokens_pattern,\n",
    "            head_module=nn.Sequential(\n",
    "                nn.Linear(config.embed_dim, config.embed_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(config.embed_dim, obs_vocab_size)\n",
    "            )\n",
    "        )\n",
    "\n",
    "#        self.head_rewards = Head(\n",
    "#            max_blocks=config.max_blocks,\n",
    "#            block_mask=act_tokens_pattern,\n",
    "#            head_module=nn.Sequential(\n",
    "#                nn.Linear(config.embed_dim, config.embed_dim),\n",
    "#                nn.ReLU(),\n",
    "#                nn.Linear(config.embed_dim, 3)\n",
    "#            )\n",
    "#        )\n",
    "\n",
    "#        self.head_ends = Head(\n",
    "#            max_blocks=config.max_blocks,\n",
    "#            block_mask=act_tokens_pattern,\n",
    "#            head_module=nn.Sequential(\n",
    "#                nn.Linear(config.embed_dim, config.embed_dim),\n",
    "#                nn.ReLU(),\n",
    "#                nn.Linear(config.embed_dim, 2)\n",
    "#            )\n",
    "#        )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"world_model\"\n",
    "\n",
    "    def forward(self, tokens: torch.LongTensor, past_keys_values: Optional[KeysValues] = None) -> WorldModelOutput:\n",
    "\n",
    "        num_steps = tokens.size(1)  # (B, T)\n",
    "        assert num_steps <= self.config.max_tokens\n",
    "        prev_steps = 0 if past_keys_values is None else past_keys_values.size\n",
    "\n",
    "        sequences = self.embedder(tokens, num_steps, prev_steps) + self.pos_emb(prev_steps + torch.arange(num_steps, device=tokens.device))\n",
    "\n",
    "        x = self.transformer(sequences, past_keys_values)\n",
    "\n",
    "        logits_observations = self.head_observations(x, num_steps=num_steps, prev_steps=prev_steps)\n",
    "        #logits_rewards = self.head_rewards(x, num_steps=num_steps, prev_steps=prev_steps)\n",
    "        #logits_ends = self.head_ends(x, num_steps=num_steps, prev_steps=prev_steps)\n",
    "\n",
    "        return WorldModelOutput(x, logits_observations)\n",
    "\n",
    "    def compute_loss(self, batch: Batch, tokenizer: Tokenizer, **kwargs: Any) -> LossWithIntermediateLosses:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            obs_tokens = tokenizer.encode(batch['observations'], should_preprocess=True).tokens  # (BL, K)\n",
    "\n",
    "        #act_tokens = rearrange(batch['actions'], 'b l -> b l 1')\n",
    "        tokens = rearrange(torch.cat((obs_tokens), dim=2), 'b l k1 -> b (l k1)')  # (B, L(K+1))\n",
    "\n",
    "        outputs = self(tokens)\n",
    "\n",
    "        labels_observations, labels_rewards, labels_ends = self.compute_labels_world_model(obs_tokens, batch['rewards'], batch['ends'], batch['mask_padding'])\n",
    "\n",
    "        logits_observations = rearrange(outputs.logits_observations[:, :-1], 'b t o -> (b t) o')\n",
    "        loss_obs = F.cross_entropy(logits_observations, labels_observations)\n",
    "        #loss_rewards = F.cross_entropy(rearrange(outputs.logits_rewards, 'b t e -> (b t) e'), labels_rewards)\n",
    "        #loss_ends = F.cross_entropy(rearrange(outputs.logits_ends, 'b t e -> (b t) e'), labels_ends)\n",
    "\n",
    "        return LossWithIntermediateLosses(loss_obs=loss_obs)\n",
    "\n",
    "    def compute_labels_world_model(self, obs_tokens: torch.Tensor, rewards: torch.Tensor, ends: torch.Tensor, mask_padding: torch.BoolTensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        assert torch.all(ends.sum(dim=1) <= 1)  # at most 1 done\n",
    "        mask_fill = torch.logical_not(mask_padding)\n",
    "        labels_observations = rearrange(obs_tokens.masked_fill(mask_fill.unsqueeze(-1).expand_as(obs_tokens), -100), 'b t k -> b (t k)')[:, 1:]\n",
    "        labels_rewards = (rewards.sign() + 1).masked_fill(mask_fill, -100).long()  # Rewards clipped to {-1, 0, 1}\n",
    "        labels_ends = ends.masked_fill(mask_fill, -100)\n",
    "        return labels_observations.reshape(-1), labels_rewards.reshape(-1), labels_ends.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_agent(self, epoch: int) -> None:\n",
    "        self.agent.train()\n",
    "        self.agent.zero_grad()\n",
    "\n",
    "        metrics_tokenizer, metrics_world_model, metrics_actor_critic = {}, {}, {}\n",
    "\n",
    "        cfg_tokenizer = self.cfg.training.tokenizer\n",
    "        cfg_world_model = self.cfg.training.world_model\n",
    "        cfg_actor_critic = self.cfg.training.actor_critic\n",
    "\n",
    "        w = self.cfg.training.sampling_weights\n",
    "\n",
    "        if epoch > cfg_tokenizer.start_after_epochs:\n",
    "            metrics_tokenizer = self.train_component(self.agent.tokenizer, self.optimizer_tokenizer, sequence_length=1, sample_from_start=True, sampling_weights=w, **cfg_tokenizer)\n",
    "        self.agent.tokenizer.eval()\n",
    "\n",
    "        if epoch > cfg_world_model.start_after_epochs:\n",
    "            metrics_world_model = self.train_component(self.agent.world_model, self.optimizer_world_model, sequence_length=self.cfg.common.sequence_length, sample_from_start=True, sampling_weights=w, tokenizer=self.agent.tokenizer, **cfg_world_model)\n",
    "        self.agent.world_model.eval()\n",
    "\n",
    "        if epoch > cfg_actor_critic.start_after_epochs:\n",
    "            metrics_actor_critic = self.train_component(self.agent.actor_critic, self.optimizer_actor_critic, sequence_length=1 + self.cfg.training.actor_critic.burn_in, sample_from_start=False, sampling_weights=w, tokenizer=self.agent.tokenizer, world_model=self.agent.world_model, **cfg_actor_critic)\n",
    "        self.agent.actor_critic.eval()\n",
    "\n",
    "        return [{'epoch': epoch, **metrics_tokenizer, **metrics_world_model, **metrics_actor_critic}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
